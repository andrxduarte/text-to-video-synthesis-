{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# text to video synthesis\n",
        "\n",
        "O repositório original está: https://modelscope.cn/models/damo/text-to-video-synthesis/summary\n",
        "\n",
        "Repositório do Hugging Face: https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis"
      ],
      "metadata": {
        "id": "L3ZmQzRrlH67"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KIrO4_Ojk2TR"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub open_clip_torch modelscope pytorch_lightning transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torchvision.io import write_video\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "if os.getenv('SYSTEM') == 'spaces':\n",
        "    os.system('pip uninstall -y modelscope')\n",
        "    os.system(\n",
        "        'pip install git+https://github.com/modelscope/modelscope.git@refs/pull/207/head'\n",
        "    )\n",
        "\n",
        "from modelscope.outputs import OutputKeys\n",
        "from modelscope.pipelines import pipeline\n",
        "\n",
        "model_dir = pathlib.Path('weights')\n",
        "if not model_dir.exists():\n",
        "    model_dir.mkdir()\n",
        "    snapshot_download('damo-vilab/modelscope-damo-text-to-video-synthesis',\n",
        "                      repo_type='model',\n",
        "                      local_dir=model_dir)\n",
        "\n",
        "pipe = pipeline('text-to-video-synthesis', model_dir.as_posix())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLah0hLXk-R9",
        "outputId": "30d6a4e6-c69c-4215-9e9a-44cc3e72b2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-20 01:36:45,077 - modelscope - INFO - PyTorch version 1.13.1+cu116 Found.\n",
            "2023-03-20 01:36:45,091 - modelscope - INFO - TensorFlow version 2.11.0 Found.\n",
            "2023-03-20 01:36:45,102 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2023-03-20 01:36:45,186 - modelscope - INFO - Loading done! Current index file version is 1.4.1, with md5 c99af2abbaffaa749d9fa0ce360b29fd and a total number of 842 components indexed\n",
            "2023-03-20 01:36:55,356 - modelscope - INFO - initiate model from weights\n",
            "2023-03-20 01:36:55,358 - modelscope - INFO - initiate model from location weights.\n",
            "2023-03-20 01:36:55,363 - modelscope - INFO - initialize model from weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt: str, seed: int) -> torch.Tensor:\n",
        "    if seed == -1:\n",
        "        seed = random.randint(0, 1000000)\n",
        "    torch.manual_seed(seed)\n",
        "    output = pipe({'text': prompt})[OutputKeys.OUTPUT_VIDEO]\n",
        "    output_tensor = torch.from_numpy(output).to(device).permute(3, 0, 1, 2)\n",
        "    return output_tensor\n",
        "\n",
        "# Testando a função generate\n",
        "output = generate(\"An astronaut riding a horse.\", 0)\n",
        "print(output.size())\n",
        "\n",
        "# Definindo exemplo\n",
        "examples = [\n",
        "    ['An astronaut riding a horse.', 0],\n",
        "    ['A panda eating bamboo on a rock.', 0],\n",
        "    ['Spiderman is surfing.', 0],\n",
        "]"
      ],
      "metadata": {
        "id": "UCVNSoLllcvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função que salva o tensor de vídeo como um arquivo mp4\n",
        "def save_video(tensor: torch.Tensor, filename: str):\n",
        "    video = tensor.permute(1, 2, 3, 0).cpu().numpy()\n",
        "    write_video(filename, video, fps=25)\n",
        "\n",
        "\n",
        "# Testando a função save_video\n",
        "save_video(output, \"output.mp4\")"
      ],
      "metadata": {
        "id": "WAQf0Sb_lg0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IF2fOdS7pXGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}